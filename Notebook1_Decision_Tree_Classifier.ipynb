{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook1_Decision_Tree_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAd2m4ePGLCl",
        "colab_type": "text"
      },
      "source": [
        "# A Notebook to Use Decision Tree Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlO9vzSQGVB2",
        "colab_type": "text"
      },
      "source": [
        "This notebook shows how to train a decision tree to classify unseen instances.\n",
        "\n",
        "For those of you interested in understanding the code, it uses predefined functions from the [sklearn](http://scikit-learn.org) library of machine learning primitives and from the [graphviz](http://www.graphviz.org) library to generate visualizations. A few more details about the code:  \n",
        "* The variable \"dataset\" stores the name of text file that you input and is passed as an argument of the function \"loadDataSet()\".  \n",
        "* The variable \"attributes\" stores the names of all features. The variable \"instances\" stores the values of all features in the training set. The variable \"labels\" stores the labels of all instances.  \n",
        "* The variable \"clf\" stores a decision tree model, and it can be trained with \"instances\" and \"labels\". Once the model is trained, it can be used to predict unseen instances.  We use a type of decision tree algorithm called CART (Classification and Regression Trees). \n",
        "* The variable \"n_foldCV\" stores the number of times of n-fold cross validation that you input.\n",
        "* The function \"cross_val_scores\" assesses the accuracy scores of a decision tree model.  Its inputs are \"clf\", \"instances\", \"labels\", \"n_foldCV\".\n",
        "* The variable \"scores\" stores the accuracy of an n-fold cross validation of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_HVmfVTGWVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://github.com/khider/INF549/blob/master/Assignment3_MachineLearning/Dataset/iris.csv\n",
        "# !wget https://github.com/khider/INF549/blob/master/Assignment3_MachineLearning/Dataset/lenses.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_aMOusiGeof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import graphviz\n",
        "\n",
        "def loadDataSet(dataset):\n",
        "    with open(dataset) as f:\n",
        "        data=f.readlines()\n",
        "        attributes=data[0].rstrip().split(',')[:-1]\n",
        "        instances=[entry.rstrip().split(',')[:-1] for entry in data[1:]]\n",
        "        dataArray=[]\n",
        "        for i in range(len(instances[0])):\n",
        "            dataArray.append([float(instance[i]) for instance in instances])\n",
        "        instances=np.array(dataArray).T\n",
        "        labels=[entry.rstrip().split(',')[-1] for entry in data[1:]]\n",
        "        return attributes,instances,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_bpkY00Gl6x",
        "colab_type": "text"
      },
      "source": [
        "## Training: Building a Decision Tree Classifier ##\n",
        "\n",
        "The cell below asks for a dataset. It trains a decision tree classifier. \n",
        "\n",
        "We provide two classification datasets that could be applied to the decision tree algorithms. \n",
        "* \"iris.csv\" has four attributes with continuous values describing three different iris species.\n",
        "* \"lenses.csv\" contains four attributes with discrete values and three classes.\n",
        "\n",
        "Before training your classifier, run the cell below to take a look at the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaGF8KJRGhQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset=input('Please Enter Your Dataset:')\n",
        "df=pd.read_csv(dataset)\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOcX98MkGsGw",
        "colab_type": "text"
      },
      "source": [
        "The following cell gives the number of instances in all distinct classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xOFuckgGsfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_name = input('Enter The Label Name:')\n",
        "print(df[label_name].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95RPiR-CG21a",
        "colab_type": "text"
      },
      "source": [
        "Before we run the following cell, let's learn an important concept called feature encoding. Many classifiers only take numerical data and some datasets have features that are not numerical. For example, a feature can be the state that a person lives in. Those are called [categorical features](https://en.wikipedia.org/wiki/Categorical_variable). In that case,we need to encode categorical features into discrete values. This process is called feature encoding\n",
        "\n",
        "In our notebook, if your dataset contains categorical features, you will see the code rules in the cell below. In the next section, when you are prompted to input test set for prediction, the algorithm will automatically encode the relevant categorical features according to the code rules showned below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCsuSUodG3Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attributes,instances,labels=loadDataSet(dataset)\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf.fit(instances,labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN9x8TJUG9HI",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing a Decision Tree##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6flkKTxaHCGk",
        "colab_type": "text"
      },
      "source": [
        "The following cell will generate a visualization of the decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOHcqZCuG_fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dot_data = tree.export_graphviz(clf, out_file=None,max_depth=5,\\\n",
        "feature_names=attributes,class_names=clf.classes_,label='all',\\\n",
        "filled=True,special_characters=True) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Yn2TOqHHKz",
        "colab_type": "text"
      },
      "source": [
        "## Prediction: Classifying New Instances Using a Decision Tree Classifier##\n",
        "\n",
        "The cell below classifies new instances with the decision tree you created.\n",
        "\n",
        "When you are prompted to input a test set, please create an example of an instance that looks like the instances in the training set.  For example, if you trained the classifier with contact lenses data, you should create an instance that has the same kinds of features.  For example:\n",
        "\n",
        "\"young,myope,yes,normal\"\n",
        "\n",
        "\n",
        "Each feature value is separated with a comma, and should have the same length as the instances in the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku7-hcl_HHfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset=input('Please Enter Your Prediction Set:')\n",
        "testset=testset.strip().split(\",\")\n",
        "temp=[]\n",
        "for i in range(len(testset)):\n",
        "        temp.append(float(testset[i]))\n",
        "testset=np.array(temp).reshape((1,len(temp)))\n",
        "predictions=clf.predict(testset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdKZpn_HMdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU67ZUzHHKi6",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the Accuracy of a Decision Tree Classifier##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFts6pt-HTVX",
        "colab_type": "text"
      },
      "source": [
        "The following cell will run cross-validation to evaluate your decision tree classifier.  It will ask you for your test data, and the number of folds that you want to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7chxB_7HWRq",
        "colab_type": "text"
      },
      "source": [
        "K Fold Cross-Validation is used to estimate prediction error. The dataset is randomly divided into K folds. The first fold acts as the validation set while the method is fit on remaining K-1 folds. Mean Squared Error is calculated on the observations from the held-out fold. The process is repeated K times, taking a different part each time. \n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=12dKPXQ3m_-283DfvC2Tgy0rOU5gnY277)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJwt-yp6HPf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=input('Please Enter Your Test Data:')\n",
        "n_foldCV=int(input(\"Please Enter the Number of Folds:\"))\n",
        "attributes,instances,labels=loadDataSet(dataset)\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(instances,labels)\n",
        "scores = cross_val_score(clf, instances, labels, cv=n_foldCV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5gXsFQcHbz8",
        "colab_type": "text"
      },
      "source": [
        "You can visualize the testing and trainging in KFold cross-validation in the following cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "457Zl10EHcPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "cmap_data = plt.cm.Paired\n",
        "cmap_cv = plt.cm.coolwarm\n",
        "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):\n",
        "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
        "\n",
        "    # Generate the training/testing visualizations for each CV split\n",
        "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
        "        # Fill in indices with the training/test groups\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[tt] = 1\n",
        "        indices[tr] = 0\n",
        "        # Visualize the results\n",
        "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
        "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
        "                   vmin=-.2, vmax=1.2)\n",
        "\n",
        "    # Plot the data classes and groups at the end\n",
        "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
        "              c=y, marker='_', lw=lw, cmap=cmap_data)\n",
        "    \n",
        "    # Formatting\n",
        "    yticklabels = list(range(n_splits)) + ['class']\n",
        "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
        "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
        "           ylim=[n_splits+2.2, -.2], xlim=[0, len(X)])\n",
        "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ElIQJXHfDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "dataset=input(\"Please Enter Your Dataset:\")\n",
        "df=pd.read_csv(dataset)\n",
        "fig, ax = plt.subplots()\n",
        "n_splits=int(input(\"Please Enter the Number of Folds:\"))\n",
        "cv = KFold(n_splits)\n",
        "class_label = input(\"Please Enter the Label Name:\")\n",
        "if class_label == \"type of iris plant\":\n",
        "  df[class_label]=df[class_label].map({'Iris-setosa':'0','Iris-versicolor':'1', 'Iris-virginica':'2'})\n",
        "  \n",
        "X = np.array(df.iloc[:, 0:4])\n",
        "y = np.array(df.iloc[:, 4:5])\n",
        "y = y.astype(np.int)\n",
        "plot_cv_indices(cv, X, y, ax, n_splits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIp1zl00HlKC",
        "colab_type": "text"
      },
      "source": [
        "The following cell will output the accuracy score for each fold and the accuracy estimate of the model under 95% confidence interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_DqDYgRHzB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Sores:\")\n",
        "[print(score) for score in scores]\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}